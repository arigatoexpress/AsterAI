# Cloud Build configuration for Autonomous Trading System
steps:
  # Build and push Docker images
  - name: 'gcr.io/cloud-builders/docker'
    args: ['build', '-t', 'gcr.io/$PROJECT_ID/aster-trading-agent:$COMMIT_SHA', '-f', 'Dockerfile.autonomous', '.']
    
  - name: 'gcr.io/cloud-builders/docker'
    args: ['push', 'gcr.io/$PROJECT_ID/aster-trading-agent:$COMMIT_SHA']
  
  # Deploy to Cloud Run
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    entrypoint: 'gcloud'
    args:
      - 'run'
      - 'deploy'
      - 'aster-trading-agent'
      - '--image'
      - 'gcr.io/$PROJECT_ID/aster-trading-agent:$COMMIT_SHA'
      - '--region'
      - 'us-central1'
      - '--platform'
      - 'managed'
      - '--allow-unauthenticated'
      - '--memory'
      - '2Gi'
      - '--cpu'
      - '2'
      - '--max-instances'
      - '10'
      - '--min-instances'
      - '1'
      - '--port'
      - '8000'
      - '--set-env-vars'
      - 'ENVIRONMENT=production,LOG_LEVEL=INFO'
      - '--set-secrets'
      - 'ASTER_API_KEY=ASTER_API_KEY:latest,ASTER_API_SECRET=ASTER_SECRET_KEY:latest'

  # Deploy data collection service
  - name: 'gcr.io/cloud-builders/docker'
    args: ['build', '-t', 'gcr.io/$PROJECT_ID/aster-data-collector:$COMMIT_SHA', '-f', 'Dockerfile.autonomous', '.']
    
  - name: 'gcr.io/cloud-builders/docker'
    args: ['push', 'gcr.io/$PROJECT_ID/aster-data-collector:$COMMIT_SHA']
  
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    entrypoint: 'gcloud'
    args:
      - 'run'
      - 'deploy'
      - 'aster-data-collector'
      - '--image'
      - 'gcr.io/$PROJECT_ID/aster-data-collector:$COMMIT_SHA'
      - '--region'
      - 'us-central1'
      - '--platform'
      - 'managed'
      - '--allow-unauthenticated'
      - '--memory'
      - '1Gi'
      - '--cpu'
      - '1'
      - '--max-instances'
      - '5'
      - '--min-instances'
      - '1'
      - '--port'
      - '8002'
      - '--set-env-vars'
      - 'ENVIRONMENT=production,LOG_LEVEL=INFO'
      - '--set-secrets'
      - 'ASTER_API_KEY=ASTER_API_KEY:latest,ASTER_API_SECRET=ASTER_SECRET_KEY:latest'

  # Deploy monitoring dashboard
  - name: 'gcr.io/cloud-builders/docker'
    args: ['build', '-t', 'gcr.io/$PROJECT_ID/aster-dashboard:$COMMIT_SHA', '-f', 'Dockerfile.autonomous', '.']
    
  - name: 'gcr.io/cloud-builders/docker'
    args: ['push', 'gcr.io/$PROJECT_ID/aster-dashboard:$COMMIT_SHA']
  
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    entrypoint: 'gcloud'
    args:
      - 'run'
      - 'deploy'
      - 'aster-dashboard'
      - '--image'
      - 'gcr.io/$PROJECT_ID/aster-dashboard:$COMMIT_SHA'
      - '--region'
      - 'us-central1'
      - '--platform'
      - 'managed'
      - '--allow-unauthenticated'
      - '--memory'
      - '1Gi'
      - '--cpu'
      - '1'
      - '--max-instances'
      - '3'
      - '--min-instances'
      - '0'
      - '--port'
      - '8000'
      - '--set-env-vars'
      - 'ENVIRONMENT=production,LOG_LEVEL=INFO'

  # Setup BigQuery datasets and tables
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        # Create BigQuery dataset
        bq mk --dataset --location=US $PROJECT_ID:aster_trading
        
        # Create market data table
        bq mk --table \
          --schema="timestamp:TIMESTAMP,symbol:STRING,open:FLOAT,high:FLOAT,low:FLOAT,close:FLOAT,volume:FLOAT,quote_volume:FLOAT,trades:INTEGER" \
          --time_partitioning_field=timestamp \
          --clustering_fields=symbol \
          $PROJECT_ID:aster_trading.market_data
        
        # Create features table
        bq mk --table \
          --schema="timestamp:TIMESTAMP,symbol:STRING,feature_name:STRING,feature_value:FLOAT" \
          --time_partitioning_field=timestamp \
          --clustering_fields=symbol,feature_name \
          $PROJECT_ID:aster_trading.features
        
        # Create trades table
        bq mk --table \
          --schema="timestamp:TIMESTAMP,symbol:STRING,side:STRING,size:FLOAT,price:FLOAT,pnl:FLOAT,strategy:STRING" \
          --time_partitioning_field=timestamp \
          --clustering_fields=symbol,strategy \
          $PROJECT_ID:aster_trading.trades
        
        # Create performance table
        bq mk --table \
          --schema="timestamp:TIMESTAMP,strategy:STRING,total_pnl:FLOAT,daily_pnl:FLOAT,win_rate:FLOAT,sharpe_ratio:FLOAT,max_drawdown:FLOAT" \
          --time_partitioning_field=timestamp \
          --clustering_fields=strategy \
          $PROJECT_ID:aster_trading.performance

  # Setup Cloud Scheduler jobs
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        # Create data collection job (every 5 minutes)
        gcloud scheduler jobs create http aster-data-collection \
          --schedule="*/5 * * * *" \
          --uri="https://aster-data-collector-$(gcloud run services describe aster-data-collector --region=us-central1 --format='value(status.url)' | sed 's|https://||')" \
          --http-method=POST \
          --time-zone="UTC" \
          --max-retry-attempts=3 \
          --max-retry-duration=300s
        
        # Create model retraining job (weekly)
        gcloud scheduler jobs create http aster-model-retraining \
          --schedule="0 2 * * 0" \
          --uri="https://aster-trading-agent-$(gcloud run services describe aster-trading-agent --region=us-central1 --format='value(status.url)' | sed 's|https://||')/retrain" \
          --http-method=POST \
          --time-zone="UTC" \
          --max-retry-attempts=3 \
          --max-retry-duration=1800s

  # Setup monitoring and alerting
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        # Create notification channel (email)
        gcloud alpha monitoring channels create \
          --display-name="Aster Trading Alerts" \
          --type=email \
          --channel-labels=email_address=your-email@example.com
        
        # Create alerting policy for daily loss limit
        gcloud alpha monitoring policies create \
          --policy-from-file=monitoring-policy.yaml

# Options
options:
  machineType: 'E2_HIGHCPU_8'
  diskSizeGb: 100
  logging: CLOUD_LOGGING_ONLY

# Substitutions
substitutions:
  _REGION: 'us-central1'

# Timeout
timeout: '1200s'
